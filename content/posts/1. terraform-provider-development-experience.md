+++
date = '2026-02-05T19:50:51+05:00'
draft = true
title = 'Terraform Provider Development Experience'
categories = ["Terraform", "Go"]
+++

Developing your own terraform provider might be required in case
you have some internal services. And that service and your terraform
modules are used by many teams. Such cases having your own provider
and distributing makes terraform code cleaner, allows to avoid glue
shell scripts.

I did develop few providers for our internal services, below want to 
list points which was interesting for me, or points which I missed
initially.

## SDK version

There is two SDK versions are available to develop provider: [SDKv2](https://developer.hashicorp.com/terraform/plugin/sdkv2) 
and [plugin framework](https://developer.hashicorp.com/terraform/plugin/framework). 
Later is newer and recommended by terraform, but that
doesn't mean SDKv2 is deprecated, it is still widely used. Probably
it will take years before all will be migrated to new one. In my case
I used only plugin framework as recommended. Also there was need to
read other providers which uses SDKv2, and there is no problems to do
that. There is differences between them but probably because of same
protocol it is easy to understand what is going on even in case of SDKv2.

## Pay attention to how import works

If you start provider development using [scaffolding app template](https://github.com/hashicorp/terraform-provider-scaffolding-framework)
then you see like this code for resource:

```go
func (r *ExampleResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	resource.ImportStatePassthroughID(ctx, path.Root("id"), req, resp)
}
```

I initially didn't pay attention much, but what is written here actually linked how 
you would implement your `Read` function. Basically it means when "import" is
happening your `Read` function will be executed, and from fields only `id`
will be available. It impacts how you define your ID, you should be able to
read resource purely by ID. It sounds easy, but in some cases resource could
be available only in nested way. For example, let's say you have resource 
by this path: `/policy/<policyID>/rules/<ruleID>`.

Initially you could select `ruleID` as id for your `PolicyRule` resource, which
brings a problem with import. For that reason probably you should make your
ID in this format `<policyID>/<ruleID>`, doing this you can fetch rule purely
by ID:

```go
func (r *ExampleResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var resourceID types.String
    req.State.GetAttribute(ctx, path.Root("resourceID"), &resourceID)

    parts := strings.Split(resourceID, "/")
    policyID := parts[0]
    ruleID := parts[1]

    // Define your http req

	// If applicable, this is a great opportunity to initialize any necessary
	// provider client data and make a call using it.
	// httpResp, err := r.client.Do(httpReq)
	// if err != nil {
	//     resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read example, got error: %s", err))
	//     return
	// }

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
```

This of course means import should be run like this:

```
terraform import <policyID>/<ruleID>
```

## Keeping client code in same repo as your provider

There was recommendation like better to not keep your client code to service
in same repository as your provider. But for me it was better option
to avoid additional maintenance as service client wasn't going
to be used by anyone else. Probably it means if your company big enough
to have internal services, but not big emough to have Go sdk's for them
don't hesitate to keep your service's client code in same repository.
Of course keep isolation between client code and provider's (mixing them
definetely not a good idea).

For me it simlified overall development, as service client and provider
implemented in same time.

## Logging approach

In terraform structured [logging](https://developer.hashicorp.com/terraform/tutorials/providers-plugin-framework/providers-plugin-framework-logging) is used. 
In my case there was need to log not only from provider, but to have logs 
from client code as well. Also I wanted to keep some isolation (in case I would need to
separate client code to separate repository). For that I implemented
interface:

```go
interface Logger {
    Debug(ctx context.Context, msg string)
    Info(ctx context.Context, msg string)
}
```

In the provider side add logger structure:

```go
type ClientLogger struct {
}

func (c *ClientLogger) Debug(ctx context.Context, msg string) {
    tflog.Debug(ctx, msg)
}

func (c *ClientLogger) Info(ctx context.Context, msg string) {
    tflog.Info(ctx, msg)
}
```

In your client code add possibility to get logger as parameter:

```go
type ExampleClient struct{
    Logger *ClientLogger
}

func (c *ExampleClient) Execute(ctx context.Context) {
    // this log appears if TF_LOG=INFO
    c.Logger.Info(ctx, "Starting execute something")
    // do something
    // add more debugging logs if needed, this log appears if TF_LOG=DEBUG
    c.Logger.Debug(ctx, "Debugging information")
}
```

In my case logging as much as possible information in case of error
was very helpful. Specially during executions of terraform in pipelines.

Also check diagnostics logis: https://developer.hashicorp.com/terraform/plugin/framework/diagnostics

